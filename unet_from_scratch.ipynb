{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNKiNByfyAntnNWRYqJpxsH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ytAg6lD2tQ_g","executionInfo":{"status":"ok","timestamp":1714022638396,"user_tz":-330,"elapsed":7298,"user":{"displayName":"a Khan","userId":"13265512739383866464"}}},"outputs":[],"source":["\n","# -*- coding: utf-8 -*-\n","\"\"\"Unet from scratch.ipynb\n","\n","Automatically generated by Colaboratory.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/15rmfqS8tVtBaqNH5c_rmV3N1RI-0raYX\n","\"\"\"\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Input, concatenate\n","from tensorflow.keras.models import Model\n","\n","#Let's create a function for one step of the encoder block, so as to increase the reusability when making custom unets\n","\n","def encoder_block(filters, inputs):\n","  x = Conv2D(filters, kernel_size = (3,3), padding = 'same', strides = 1, activation = 'relu')(inputs)\n","  s = Conv2D(filters, kernel_size = (3,3), padding = 'same', strides = 1, activation = 'relu')(x)\n","  p = MaxPooling2D(pool_size = (2,2), padding = 'same')(s)\n","  return s, p #p provides the input to the next encoder block and s provides the context to the symmetrically opposte decoder block\n","\n","#Baseline layer is just a binch on Convolutional Layers to extract high level features from the downsampled Image\n","#As the number of baselines to include is highly related to the task, we don't necessarily need a function for it\n","def baseline_layer(filters, inputs):\n","  x = Conv2D(filters, kernel_size = (3,3), padding = 'same', strides = 1, activation = 'relu')(inputs)\n","  x = Conv2D(filters, kernel_size = (3,3), padding = 'same', strides = 1, activation = 'relu')(x)\n","  return x\n","\n","#Decoder Block\n","\n","def decoder_block(filters, connections, inputs):\n","  x = Conv2DTranspose(filters, kernel_size = (2,2), padding = 'same', activation = 'relu', strides = 2)(inputs)\n","  skip_connections = concatenate([x, connections], axis = -1)\n","  x = Conv2D(filters, kernel_size = (2,2), padding = 'same', activation = 'relu')(skip_connections)\n","  x = Conv2D(filters, kernel_size = (2,2), padding = 'same', activation = 'relu')(x)\n","  return x\n","\n","def unet():\n","  #Defining the input layer and specifying the shape of the images\n","  inputs = Input(shape = (256,256,1))\n","\n","  #defining the encoder\n","  s1, p1 = encoder_block(64, inputs = inputs)\n","  s2, p2 = encoder_block(128, inputs = p1)\n","  s3, p3 = encoder_block(256, inputs = p2)\n","  s4, p4 = encoder_block(512, inputs = p3)\n","\n","  #Setting up the baseline\n","  baseline = baseline_layer(1024, p4)\n","\n","  #Defining the entire decoder\n","  d1 = decoder_block(512, s4, baseline)\n","  d2 = decoder_block(256, s3, d1)\n","  d3 = decoder_block(128, s2, d2)\n","  d4 = decoder_block(64, s1, d3)\n","\n","  #Setting up the output function for binary classification of pixels\n","  outputs = Conv2D(1, 1, activation = 'sigmoid')(d4)\n","\n","  #Finalizing the model\n","  model = Model(inputs = inputs, outputs = outputs, name = 'Unet')\n","\n","  return model\n"]}]}